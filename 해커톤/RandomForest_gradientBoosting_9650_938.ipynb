{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mzhhVZa7L1w3"
   },
   "source": [
    "# INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#레전드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "input_data = pd.read_csv(\"2023_smartFarm_AI_hackathon_dataset.csv\")\n",
    "\n",
    "X = input_data[input_data.drop(columns=['Mist Cost', 'MistUsageTime', 'CO2Cost', 'CO2Usage', 'FertilizerCost', 'FertilizerUsage', 'WaterCost', 'WaterUsage', 'frtstJnt', 'hvstCo', 'flwrCo', 'hvstJnt', 'tcdmt', 'flanJnt', 'pllnLt','lefstalklt','outWs','daysuplyqy', 'outtrn_cumsum', 'frmDist']).columns]      \n",
    "Y = input_data['outtrn_cumsum'].values.ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid 또는 Randomaized search 이용 - 하이퍼 파라미터 튜닝\n",
    "\n",
    "# 랜덤 포레스트 회귀 모델\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_ = {\n",
    "    'n_estimators': [100, 200, 300],  # 트리의 개수\n",
    "    'max_depth': [None, 10, 20, 30],  # 최대 트리 깊이\n",
    "    'min_samples_split': [2, 5, 10],  # 노드를 분할하기 위한 최소한의 샘플 개수\n",
    "    'min_samples_leaf': [1, 2, 4]  # 리프 노드에 필요한 최소한의 샘플 개수\n",
    "}\n",
    "\n",
    "#grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "random_search = RandomizedSearchCV(rf_model, param_, cv=5, n_iter=5) # n_iter개 조합을 랜덤으로 뽑아서 최적인 거 선정\n",
    "\n",
    "#best_model = grid_search.fit(X_train, y_train)\n",
    "best_model = random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 얻습니다.\n",
    "print(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9650.39978142376\n",
      "R2_score: 0.938676285749752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "def calculate_rmse(targets, predictions):\n",
    "    return np.sqrt(mean_squared_error(targets, predictions))\n",
    "\n",
    "rmse = calculate_rmse(y_test, y_pred)\n",
    "\n",
    "r2score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2_score:\", r2score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
